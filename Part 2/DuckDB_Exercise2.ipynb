{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DuckDB_Exercise2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4UIW8GUQaqt"
      },
      "source": [
        "# **SETUP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXvRwAVPGtiX"
      },
      "source": [
        "First we need to install DuckDB again.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFC0Acb9Gu8W"
      },
      "source": [
        "!pip install duckdb --pre"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryMJZSckLmqG"
      },
      "source": [
        "# **Loading The Data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDQF0N7HJIQ_"
      },
      "source": [
        "Now we download the dataset and decompress it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RXn51F_JMpn"
      },
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "print(\"Downloading datasets\")\n",
        "\n",
        "urllib.request.urlretrieve(\"https://github.com/Mytherin/datasets/raw/main/tpch_sf01.zip\", \"tpch_sf01.zip\")\n",
        "\n",
        "print(\"Decompressing files\")\n",
        "\n",
        "with zipfile.ZipFile(\"tpch_sf01.zip\",\"r\") as zip_ref:\n",
        "\tzip_ref.extractall(\"./\")\n",
        "\t\n",
        "print(\"Finished.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJSvVxkOL6af"
      },
      "source": [
        "We load the data set into DuckDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBPmYEMLNQ63"
      },
      "source": [
        "import duckdb\n",
        "con = duckdb.connect(':memory:')\n",
        "\n",
        "queries = []\n",
        "with open('tpch_sf01/schema.sql', 'r') as f:\n",
        "  queries += [x for x in f.read().split(';') if len(x.strip()) > 0]\n",
        "with open('tpch_sf01/load.sql', 'r') as f:\n",
        "  queries += [x for x in f.read().split(';') if len(x.strip()) > 0]\n",
        "\n",
        "print(\"Beginning data load\")\n",
        "for q in queries:\n",
        "  con.execute(q)\n",
        "print(\"Finishing data load\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQCvdodnNpKl"
      },
      "source": [
        "# **Inspecting the Query Plan**\n",
        "The query plan of a query can be inspected by prefixing the query with`explain`. By default, only the physical query plan is returned. You can use `PRAGMA explain_output='all'` to output the unoptimized logical plan, the optimized logical plan and the physical plan instead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU6-xxAWNth9"
      },
      "source": [
        "def explain_query(query):\n",
        "  print(con.execute(\"EXPLAIN \" + query).fetchall()[0][1])\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT l_orderkey, SUM(l_extendedprice)\n",
        "FROM lineitem\n",
        "WHERE l_discount < 5\n",
        "GROUP BY l_orderkey\n",
        "ORDER BY l_orderkey DESC;\n",
        "\"\"\"\n",
        "\n",
        "explain_query(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKAtnEB2PuCp"
      },
      "source": [
        "# **Profiling Queries**\n",
        "Rather than only viewing the query plan, we can also run the query and look at the profile output. The function `run_and_profile_query` below performs this profiling by enabling the profiling, writing the profiling output to a file, and then printing the contents of that file to the console.\n",
        "\n",
        "The profiler output shows extra information for every operator; namely how much time was spent executing that operator, and how many tuples have moved from that operator to the operator above it. \n",
        "\n",
        "For a `SEQ_SCAN` (sequential scan), for example, it shows how many tuples have been read from the base table. For a `FILTER`, it shows how many tuples have passed the filter predicate. For a `HASH_GROUP_BY`, it shows how many groups were created and aggregated.\n",
        "\n",
        "These intermediate cardinalities are important because they do a good job of explaining why an operator takes a certain amount of time, and in many cases these intermediates can be avoided or drastically reduced by modifying the way in which a query is executed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejriXVhQP1X2"
      },
      "source": [
        "def run_and_profile_query(query):\n",
        "  con.execute(\"PRAGMA enable_profiling\")\n",
        "  con.execute(\"PRAGMA profiling_output='out.log'\")\n",
        "  con.execute(query)\n",
        "  with open('out.log', 'r') as f:\n",
        "    output = f.read()\n",
        "  con.execute(\"PRAGMA disable_profiling\")\n",
        "  print(output)\n",
        "  \n",
        "query = \"\"\"\n",
        "SELECT l_orderkey, SUM(l_extendedprice)\n",
        "FROM lineitem\n",
        "WHERE l_discount < 5\n",
        "GROUP BY l_orderkey\n",
        "ORDER BY l_orderkey DESC;\n",
        "\"\"\"\n",
        "\n",
        "run_and_profile_query(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRNkx2dK7_wZ"
      },
      "source": [
        "\n",
        "# **Query Optimizations**\n",
        "\n",
        "An important component of a database system is the optimizer. The optimizer changes the query plan so that it is logically equivalent to the original plan, but (hopefully) executes much faster.\n",
        "\n",
        "In an ideal world, the optimizer allows the user not to worry about how to formulate a query: the user only needs to describe what result they want to see, and the database figures out the most efficient way of retrieving that result.\n",
        "\n",
        "In practice, this is certainly not always true, and in some situations it is necessary to rephrase a query. Nevertheless, optimizers generally do a very good job at optimizing queries, and save users a lot of time in manually reformulating queries.\n",
        "\n",
        "Let us run the following query and see how it performs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5dTktM58Dje"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        "    l_orderkey,\n",
        "    sum(l_extendedprice * (1 - l_discount)) AS revenue,\n",
        "    o_orderdate,\n",
        "    o_shippriority\n",
        "FROM\n",
        "    customer,\n",
        "    orders,\n",
        "    lineitem\n",
        "WHERE\n",
        "    c_mktsegment = 'BUILDING'\n",
        "    AND c_custkey = o_custkey\n",
        "    AND l_orderkey = o_orderkey\n",
        "    AND o_orderdate < CAST('1995-03-15' AS date)\n",
        "    AND l_shipdate > CAST('1995-03-15' AS date)\n",
        "GROUP BY\n",
        "    l_orderkey,\n",
        "    o_orderdate,\n",
        "    o_shippriority\n",
        "ORDER BY\n",
        "    revenue DESC,\n",
        "    o_orderdate\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "run_and_profile_query(query)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyDSVNG1TmPi"
      },
      "source": [
        "\n",
        "\n",
        "# **Manual Query Optimizations**\n",
        "\n",
        "In order to get a better idea of how query optimizers work, we are going to perform *manual* query optimization. In order to do that, we will disable all query optimizers in DuckDB, which means the query will run *as-is*. We can then change the way the query is physically executed by altering the query. Let's try to disable the optimizer and looking at the query plan:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy7O9XS0T9kJ"
      },
      "source": [
        "con.execute(\"PRAGMA disable_optimizer\")\n",
        "explain_query(query)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnE6A2olT954"
      },
      "source": [
        "Looking at the plan you now see that the hash joins that were used before are replaced by cross products followed by a filter. This is what was literally written in the query, however, cross products are extremely expensive! We could run this query, but because of the cross products it will take extremely long. \n",
        "\n",
        "Let's rewrite the query to explicitly use joins instead, and then we can actually run it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oypnNM8qZel2"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        "    l_orderkey,\n",
        "    sum(l_extendedprice * (1 - l_discount)) AS revenue,\n",
        "    o_orderdate,\n",
        "    o_shippriority\n",
        "FROM\n",
        "    customer\n",
        "    JOIN orders ON (c_custkey=o_custkey)\n",
        "    JOIN lineitem ON (l_orderkey=o_orderkey)\n",
        "WHERE\n",
        "    c_mktsegment = 'BUILDING'\n",
        "    AND o_orderdate < CAST('1995-03-15' AS date)\n",
        "    AND l_shipdate > CAST('1995-03-15' AS date)\n",
        "GROUP BY\n",
        "    l_orderkey,\n",
        "    o_orderdate,\n",
        "    o_shippriority\n",
        "ORDER BY\n",
        "    revenue DESC,\n",
        "    o_orderdate\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "run_and_profile_query(query)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNEso9LqaXYw"
      },
      "source": [
        "# **Assignment**\n",
        "\n",
        "Now the query actually finishes; however, it is still much slower than before. There are more changes that can be made to the query to make it run faster. Your assignment (and challenge!) is to adjust the query so that it runs in similar speed to the query with optimizations enabled. You will be the human query optimizer replacing the disabled one.\n",
        "\n",
        "Hint:\n",
        "\n",
        "1. Join order matters!\n",
        "2. DuckDB always builds the hash table on the *right side* of a hash join.\n",
        "3. Filters? Projections?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M2rSHRlamG3"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        "    l_orderkey,\n",
        "    sum(l_extendedprice * (1 - l_discount)) AS revenue,\n",
        "    o_orderdate,\n",
        "    o_shippriority\n",
        "FROM\n",
        "    customer\n",
        "    JOIN orders ON (c_custkey=o_custkey)\n",
        "    JOIN lineitem ON (l_orderkey=o_orderkey)\n",
        "WHERE\n",
        "    c_mktsegment = 'BUILDING'\n",
        "    AND o_orderdate < CAST('1995-03-15' AS date)\n",
        "    AND l_shipdate > CAST('1995-03-15' AS date)\n",
        "GROUP BY\n",
        "    l_orderkey,\n",
        "    o_orderdate,\n",
        "    o_shippriority\n",
        "ORDER BY\n",
        "    revenue DESC,\n",
        "    o_orderdate\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "run_and_profile_query(query)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhBLdZ0XTnG7"
      },
      "source": [
        "# **Bonus Assignment**\n",
        "\n",
        "As a bonus assignment, here is another query that you can optimize. Note that this query is currently NOT fully optimized by DuckDB because of a problem in the query optimizer, hence on this query it is actually possible to not only match, but beat the DuckDB query optimizer!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYS2uTs1BB-q"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        "    nation,\n",
        "    o_year,\n",
        "    sum(amount) AS sum_profit\n",
        "FROM (\n",
        "    SELECT\n",
        "        n_name AS nation,\n",
        "        extract(year FROM o_orderdate) AS o_year,\n",
        "        l_extendedprice * (1 - l_discount) - ps_supplycost * l_quantity AS amount\n",
        "    FROM\n",
        "        part,\n",
        "        supplier,\n",
        "        lineitem,\n",
        "        partsupp,\n",
        "        orders,\n",
        "        nation\n",
        "    WHERE\n",
        "        s_suppkey = l_suppkey\n",
        "        AND ps_suppkey = l_suppkey\n",
        "        AND ps_partkey = l_partkey\n",
        "        AND p_partkey = l_partkey\n",
        "        AND o_orderkey = l_orderkey\n",
        "        AND s_nationkey = n_nationkey\n",
        "        AND p_name LIKE '%green%') AS profit\n",
        "GROUP BY\n",
        "    nation,\n",
        "    o_year\n",
        "ORDER BY\n",
        "    nation,\n",
        "    o_year DESC;\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# HINT: first replace the cross products with joins before running this query!\n",
        "# run_and_profile_query(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZXJm1urWj15"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}